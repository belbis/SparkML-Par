/*
 * Copyright (c) 2018 Machine Zone Inc. All rights reserved.
 */
package org.apache.spark.ml.feature.parallel

import org.apache.spark.ml.Model
import org.apache.spark.ml.feature.{MinMaxScaler, MinMaxScalerModel, MinMaxScalerParams}
import org.apache.spark.ml.util.Identifiable

/**
  * ParallelMinMaxScaler
  *
  * [[MinMaxScaler]] that operates on multiple input columns.
  *
  * @author belbis
  * @since 1.0.0
  */
class ParallelMinMaxScaler(override val uid: String)
  extends ParallelEstimator[ParallelMinMaxScalerModel, MinMaxScalerModel]
    with MinMaxScalerParams {

  // NOTE: uid must be defined in the constructor or you will see errors a la
  // https://issues.apache.org/jira/browse/SPARK-12606
  def this() = this(Identifiable.randomUID("ParallelMinMaxScaler"))

  /**
    * createStage
    *
    * Create new instance of [[MinMaxScaler]].
    *
    * @param inputColumn
    * @return
    */
  override def createStage(inputColumn: String): MinMaxScaler = {
    new MinMaxScaler().setMin($(min)).setMax($(max))
  }

  /**
    * createModel
    *
    * Create new instance pf [[ParallelMinMaxScalerModel]].
    *
    * @param models
    * @return
    */
  override def createModel(models: Map[String, MinMaxScalerModel]): ParallelMinMaxScalerModel = {
    new ParallelMinMaxScalerModel()
      .setInputCols($(inputCols))
      .setParents($(stages))
      .setStages(models)
  }

}

/**
  * ParallelMinMaxScalerModel
  *
  * [[Model]] generated by falling #fit() on [[ParallelStandardScaler]].
  *
  * @param uid
  * @author belbis
  * @since 1.0.0
  */
class ParallelMinMaxScalerModel(override val uid: String)
  extends Model[ParallelMinMaxScalerModel] with ParallelModel[MinMaxScalerModel] {

  // NOTE: uid must be defined in the constructor or you will see errors a la
  // https://issues.apache.org/jira/browse/SPARK-12606
  def this() = this(Identifiable.randomUID("ParallelMinMaxScalerModel"))

}
