/*
 * Copyright (c) 2018 Machine Zone Inc. All rights reserved.
 */
package org.apache.spark.ml.feature.parallel

import org.apache.spark.ml.Model
import org.apache.spark.ml.feature.{MaxAbsScaler, MaxAbsScalerModel, MaxAbsScalerParams}
import org.apache.spark.ml.util.Identifiable

/**
  * ParallelMaxAbsScaler
  *
  * [[MaxAbsScaler]] that operates on multiple input columns.
  *
  * @author belbis
  * @since 1.0.0
  */
class ParallelMaxAbsScaler(override val uid: String)
  extends ParallelEstimator[ParallelMaxAbsScalerModel, MaxAbsScalerModel]
    with MaxAbsScalerParams {

  // NOTE: uid must be defined in the constructor or you will see errors a la
  // https://issues.apache.org/jira/browse/SPARK-12606
  def this() = this(Identifiable.randomUID("ParallelMaxAbsScaler"))

  /**
    * createStage
    *
    * Create new instance of [[MaxAbsScaler]].
    *
    * @param inputColumn
    * @return
    */
  override def createStage(inputColumn: String): MaxAbsScaler = {
    new MaxAbsScaler()
      .setInputCol(inputColumn)
      .setOutputCol($(outputCols)($(inputCols).indexOf(inputColumn)))
  }

  /**
    * createModel
    *
    * Create new instance pf [[ParallelMaxAbsScalerModel]].
    *
    * @param models
    * @return
    */
  override def createModel(models: Map[String, MaxAbsScalerModel]): ParallelMaxAbsScalerModel = {
    new ParallelMaxAbsScalerModel()
      .setInputCols($(inputCols))
      .setParents($(stages))
      .setStages(models)
  }

}

/**
  * ParallelMaxAbsScalerModel
  *
  * [[Model]] generated by falling #fit() on [[ParallelStandardScaler]].
  *
  * @param uid
  * @author belbis
  * @since 1.0.0
  */
class ParallelMaxAbsScalerModel(override val uid: String)
  extends Model[ParallelMaxAbsScalerModel] with ParallelModel[MaxAbsScalerModel] {

  // NOTE: uid must be defined in the constructor or you will see errors a la
  // https://issues.apache.org/jira/browse/SPARK-12606
  def this() = this(Identifiable.randomUID("ParallelMaxAbsScalerModel"))

}
